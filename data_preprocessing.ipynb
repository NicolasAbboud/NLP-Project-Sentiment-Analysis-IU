{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation - Step 1\n",
    "__________________________\n",
    "\n",
    "Preparing the overall data for later classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import core libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import os \n",
    "import shutil\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve dataset from source, establish required directory structure, delete directory related to unsupervised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "\u001b[1m84125825/84125825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m697s\u001b[0m 8us/step\n"
     ]
    }
   ],
   "source": [
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "dataset = tf.keras.utils.get_file(\"aclImdb_v1.tar.gz\", url, untar=True, cache_subdir=\"./\", cache_dir=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imdb.vocab', 'imdbEr.txt', 'README', 'test', 'train']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir = os.path.join(os.path.dirname(dataset), \"aclImdb\")\n",
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labeledBow.feat',\n",
       " 'neg',\n",
       " 'pos',\n",
       " 'unsup',\n",
       " 'unsupBow.feat',\n",
       " 'urls_neg.txt',\n",
       " 'urls_pos.txt',\n",
       " 'urls_unsup.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = os.path.join(\"aclImdb\"+\"/\",\"train\" )\n",
    "os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dir = os.path.join(train_dir, \"unsup\")\n",
    "shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the Text Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize spacy basics, prepare stop word list, convert it to set (improved computation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import re \n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stop_words.remove(\"not\")\n",
    "stop_words.remove(\"nor\")\n",
    "stop_words.remove(\"no\")\n",
    "stop_words.remove(\"again\")\n",
    "add_stopwords  = set([\"movie\", \"film\", \"one\", \"the\", \"scene\", \"this\", \"story\", \"would\", \"really\", \"and\", \"also\", ])\n",
    "\n",
    "stop_words = stop_words.union(add_stopwords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove html tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(text):\n",
    "    text = re.sub(r\"<[\\w]+ />\", \" \", text)\n",
    "    text = re.sub(\"n't\", \" not\", text)\n",
    "    return text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean text in general, stopwords removal and lemmatizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\b\\w{1,1}\\b\", \" \", text)                                                     # remove single characters\n",
    "    text = re.sub(r\"[^a-z]\", \" \", text)                                                          # remove everything which aren't letters\n",
    "    text = re.sub(r\"[\\s]+\", \" \", text)                                                           # remove too many whitespaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove PERSON tokens and Stop words:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_filter_non_entities(text):\n",
    "    doc = nlp(text)\n",
    "    non_entity_lemmas = [token.lemma_ for token in doc if token.ent_type_ != \"PERSON\"]\n",
    "    non_entity_lemmas = [token for token in non_entity_lemmas if token.lower() not in stop_words]\n",
    "    text = \" \".join(non_entity_lemmas) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply preprocessing steps on text files and save the files in new directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "def process_files_in_directory(input_directory, output_directory):\n",
    "    for root, dirs, files in os.walk(input_directory):\n",
    "        for file in files:\n",
    "            input_file_path = os.path.join(root, file)\n",
    "            with open(input_file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "\n",
    "            text_removed_html = remove_html(content)\n",
    "            text_removed_ents = process_and_filter_non_entities(text_removed_html)\n",
    "            processed_content = clean_text(text_removed_ents)\n",
    "\n",
    "            # Create the output directory if it doesn't exist\n",
    "            output_subdirectory = os.path.join(output_directory, os.path.relpath(root, input_directory))\n",
    "            os.makedirs(output_subdirectory, exist_ok=True)\n",
    "\n",
    "            # Save the processed content to a new file in the output directory\n",
    "            output_file_path = os.path.join(output_subdirectory, file)\n",
    "            with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(processed_content)\n",
    "\n",
    "input_pos_directory = './aclImdb/train/pos'\n",
    "input_neg_directory = './aclImdb/train/neg'\n",
    "\n",
    "output_pos_directory = './dataset/train/pre_final/pos'\n",
    "output_neg_directory = './dataset/train/pre_final/neg'\n",
    "\n",
    "process_files_in_directory(input_pos_directory, output_pos_directory)\n",
    "process_files_in_directory(input_neg_directory, output_neg_directory)\n",
    "\n",
    "\n",
    "input_pos_directory_test = './aclImdb/test/pos'\n",
    "input_neg_directory_test = './aclImdb/test/neg'\n",
    "\n",
    "output_pos_directory_test = './dataset/test/pre_final/pos'\n",
    "output_neg_directory_test = './dataset/test/pre_final/neg'\n",
    "\n",
    "process_files_in_directory(input_pos_directory_test, output_pos_directory_test)\n",
    "process_files_in_directory(input_neg_directory_test, output_neg_directory_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "repeat last step with training and testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation - Step 2\n",
    "__________________________\n",
    "\n",
    "For easier working with scikit-learn algorithms, the text files will be converted into .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directories containing text files\n",
    "input_directory_pos = \"./dataset/test/pre_final/pos\"\n",
    "input_directory_neg = \"./dataset/test/pre_final/neg\"\n",
    "\n",
    "# Output CSV file\n",
    "output_csv_file = \"./dataset/testing_set_preprocessed.csv\"\n",
    "\n",
    "# Function to process each text file\n",
    "def process_text_file(file_path, label):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "        new_column_value = label\n",
    "        return content, new_column_value\n",
    "\n",
    "data_list = []\n",
    "\n",
    "# Process \"positive\" directory\n",
    "for filename in os.listdir(input_directory_pos):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(input_directory_pos, filename)\n",
    "        content, new_column_value = process_text_file(file_path, \"pos\")\n",
    "        data_list.append([content, new_column_value])\n",
    "\n",
    "# Process \"negative\" directory\n",
    "for filename in os.listdir(input_directory_neg):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(input_directory_neg, filename)\n",
    "        content, new_column_value = process_text_file(file_path, \"neg\")\n",
    "        data_list.append([content, new_column_value])\n",
    "\n",
    "# CSV headers\n",
    "csv_headers = [\"review\", \"sentiment\"]\n",
    "\n",
    "df = pd.DataFrame(data_list, columns=csv_headers)\n",
    "df.to_csv(output_csv_file, index=False)\n",
    "\n",
    "# Directories containing training text files\n",
    "input_directory_pos_train = \"./dataset/train/pre_final/pos\"\n",
    "input_directory_neg_train = \"./dataset/train/pre_final/neg\"\n",
    "\n",
    "# Output CSV file for training set\n",
    "output_csv_file_train = \"./dataset/training_set_preprocessed.csv\"\n",
    "\n",
    "data_list_train = []\n",
    "\n",
    "# Process \"positive\" training reviews\n",
    "for filename in os.listdir(input_directory_pos_train):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(input_directory_pos_train, filename)\n",
    "        content, label = process_text_file(file_path, \"pos\")\n",
    "        data_list_train.append([content, label])\n",
    "\n",
    "# Process \"negative\" training reviews\n",
    "for filename in os.listdir(input_directory_neg_train):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(input_directory_neg_train, filename)\n",
    "        content, label = process_text_file(file_path, \"neg\")\n",
    "        data_list_train.append([content, label])\n",
    "\n",
    "# Save training CSV\n",
    "df_train = pd.DataFrame(data_list_train, columns=csv_headers)\n",
    "df_train.to_csv(output_csv_file_train, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go see last night coax friend mine admit reluc...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actor turn director follow promising debut got...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recreational golfer knowledge sport history pl...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>see sneak preview delightful cinematography un...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>take true us golf open make much extra ordinar...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>occasionally let kid watch garbage understand ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>anymore pretty much reality tv show people mak...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>basic genre thriller intercut uncomfortable me...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>four thing intrigue firstly star carly pope po...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>comment nearby exceptionally well write inform...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      go see last night coax friend mine admit reluc...       pos\n",
       "1      actor turn director follow promising debut got...       pos\n",
       "2      recreational golfer knowledge sport history pl...       pos\n",
       "3      see sneak preview delightful cinematography un...       pos\n",
       "4      take true us golf open make much extra ordinar...       pos\n",
       "...                                                  ...       ...\n",
       "24995  occasionally let kid watch garbage understand ...       neg\n",
       "24996  anymore pretty much reality tv show people mak...       neg\n",
       "24997  basic genre thriller intercut uncomfortable me...       neg\n",
       "24998  four thing intrigue firstly star carly pope po...       neg\n",
       "24999  comment nearby exceptionally well write inform...       neg\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(output_csv_file)\n",
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bromwell high cartoon comedy run time program ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>homelessness houselessness state issue year ne...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brilliant act well dramatic hobo lady ever see...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>easily underrated inn brooks cannon sure flawe...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not typical much less slapstick actually plot ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>towards end feel technical feel like classroom...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>kind enemy content watch time not bloody true ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>see descent last night stockholm festival huge...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>pick pound turn rather good rd century release...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>dumb ever see rip nearly ever type thriller ma...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      bromwell high cartoon comedy run time program ...       pos\n",
       "1      homelessness houselessness state issue year ne...       pos\n",
       "2      brilliant act well dramatic hobo lady ever see...       pos\n",
       "3      easily underrated inn brooks cannon sure flawe...       pos\n",
       "4      not typical much less slapstick actually plot ...       pos\n",
       "...                                                  ...       ...\n",
       "24995  towards end feel technical feel like classroom...       neg\n",
       "24996  kind enemy content watch time not bloody true ...       neg\n",
       "24997  see descent last night stockholm festival huge...       neg\n",
       "24998  pick pound turn rather good rd century release...       neg\n",
       "24999  dumb ever see rip nearly ever type thriller ma...       neg\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv(output_csv_file_train)\n",
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation - Step 3\n",
    "__________________________\n",
    "\n",
    "This is one leftover from preparing the preprocessing steps: visualizing the Named Entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">go see \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    last night\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       " coax friend mine admit reluctant see know able comedy wrong kutcher play character well play professionalism sign good toy emotion exactly entire theater sell overcome laughter \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    first\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    half\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " move tear \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    second\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " half exit theater not see many woman tear many full grown man well try desperately not let anyone see cry great suggest go see judge </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def process_and_filter_entities(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    colors = {'PERSON': 'cyan'}\n",
    "    options = {'colors': colors}\n",
    "\n",
    "    displacy.render(doc, style=\"ent\", options=options, page=False)\n",
    "\n",
    "text_to_visualize = data[\"review\"][0]\n",
    "\n",
    "process_and_filter_entities(text_to_visualize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
