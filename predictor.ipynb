{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a2dc906",
   "metadata": {},
   "source": [
    "## Predictor Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b13f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import tensorflow as tf\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "366fbdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Setup stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stop_words -= {\"not\", \"nor\", \"no\", \"again\"}\n",
    "add_stopwords = set([\"movie\", \"film\", \"one\", \"the\", \"scene\",\n",
    "                     \"this\", \"story\", \"would\", \"really\", \"and\", \"also\"])\n",
    "stop_words = stop_words.union(add_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2c9c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing functions\n",
    "def remove_html(text):\n",
    "    text = re.sub(r\"<[\\w]+ />\", \" \", text)\n",
    "    text = re.sub(\"n't\", \" not\", text)\n",
    "    return text\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\b\\w{1,1}\\b\", \" \", text)  # remove single characters\n",
    "    text = re.sub(r\"[^a-z]\", \" \", text)       # keep letters only\n",
    "    text = re.sub(r\"\\s+\", \" \", text)          # collapse whitespace\n",
    "    return text\n",
    "\n",
    "def process_and_filter_non_entities(text):\n",
    "    doc = nlp(text)\n",
    "    non_entity_lemmas = [token.lemma_ for token in doc if token.ent_type_ != \"PERSON\"]\n",
    "    non_entity_lemmas = [token for token in non_entity_lemmas if token.lower() not in stop_words]\n",
    "    return \" \".join(non_entity_lemmas)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = remove_html(text)\n",
    "    text = process_and_filter_non_entities(text)\n",
    "    text = clean_text(text)\n",
    "    return text\n",
    "\n",
    "def preprocess_text_inference(text):\n",
    "    text = remove_html(text)\n",
    "    # Only clean text (lowercase, remove extra spaces)\n",
    "    text = clean_text(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cf0bce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function\n",
    "def predict_sentiment(model, text):\n",
    "    # Preprocess the input\n",
    "    processed_text = preprocess_text_inference(text)\n",
    "    \n",
    "    # If text is very short, repeat it to mimic longer review\n",
    "    word_count = len(processed_text.split())\n",
    "    if word_count < 20:  # threshold\n",
    "        repeat_times = (20 // word_count) + 1  # repeat enough times\n",
    "        processed_text = \" \".join([processed_text] * repeat_times)\n",
    "    \n",
    "    # Convert to tensor (required by TextVectorization layer)\n",
    "    text_tensor = tf.constant([processed_text])\n",
    "    \n",
    "    # Get model logits\n",
    "    logits = model.predict(text_tensor, verbose=0)\n",
    "    \n",
    "    # Convert logits to probability\n",
    "    prob = tf.nn.sigmoid(logits[0]).numpy().item()\n",
    "    # prob = prob + 0.2\n",
    "    \n",
    "    # Determine sentiment\n",
    "    sentiment = \"Positive :)\" if prob > 0.5 else \"Negative :(\"\n",
    "    \n",
    "    # Print result\n",
    "    print(f\"Review preview: {text[:120]}...\")\n",
    "    print(f\"Sentiment: {sentiment} (score={prob:.4f})\")\n",
    "    \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24ec7843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 7 variables whereas the saved optimizer has 12 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained model\n",
    "model_path = \"./models/model_NN_final.keras\"\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1650b1",
   "metadata": {},
   "source": [
    "## Enter your review here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2096e33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"the movie is funny!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abde71e5",
   "metadata": {},
   "source": [
    "## Enjoy sentiment prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4990880d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review preview: the movie is funny!...\n",
      "Sentiment: Positive :) (score=0.8704)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8703766465187073"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8bb495",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
